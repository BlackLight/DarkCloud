\chapter{Soluzioni alto livello}
In questo capitolo si procederà a illustrare le scelte progettuali, il funzionamento a livello logico funzionale del software e della rete che sta dietro darkcloud.
\section{Ingegnerizzazione del problema}
Come discusso nel capitolo precedente la sfida che ci è stata posta è stata di fornire ad un gruppo di professionisti uno strumento per poter
condividere file in modo sicuro. Questo richiede specifiche caratteristiche sia nelle scelte di progettazione della struttura di rete sia nelle scelte di soluzioni adottate nella programmazione del codice.

L'avvento del cloud computing ci ha dato uno strumento molto potente che volevamo sfruttare per questo progetto, lo studio delle tecnologie di condivisione di file, peer to peer, ci ha dato una visione di insieme di quello che nel corso del tempo è stata l'evoluzione di queste reti. Questo studio ci ha permesso di avere molti spunti per poi tracciare quello che sarebbe stato il disegno della nostra soluzione. 
La dinamicità di alcune reti p2p pure, ad una prima analisi pareva una ottima soluzione, visto che ci avrebbe permesso di realizzare reti che si ampliassero in modo automatico e quindi non sarebbe stato necessario ogni volta che si aggiungeva un server o un client andare a riconfigurare tutti i nodi. Il problema della sicurezza però in una soluzione del genere rendeva molto più complicato verificare che i nodi aggiunti fossero nodi fidati. In una architettura p2p pura inoltre il carico di lavoro è equamente distribuito su tutti nodi in maniera indistinta, questo però nel nostro caso non sarebbe stato adatto, in quanto avendo a disposizione una grande potenza di calcolo e grande larghezza di banda da parte dei nodi cloud contenuti in grandi data-center avremmo inutilmente sobbarcato di lavoro i calcolatori degli utenti ultimi che devono invece solo caricare file e poi scaricarli.  Un altro aspetto che ci ha spinto a scartare l'approccio p2p puro è il carico di lavoro che avrebbe portato realizzare una soluzione altamente dinamica rispetto ad una soluzione statica. La programmazione di un software dinamico richiede molte più parti e una complessità totale molto maggiore. Quindi bisogna chiedersi principalmente a chi è indirizzato il nostro tipo di software, quale sarà il suo bacino di utenza, se si intende farlo crescere in futuro e cosi via, cercando quindi di impiegare la giusta quantità di risorse.
Non ha senso realizzare un software e una architettura che sopporti migliaia di utenti quando è specificamente richiesto che funzioni per poche decine di persone.

Oggi non è difficile utilizzare un server centrale per concentrare tutte le informazioni e i dati di una azienda, anzi è proprio quello che fanno la maggior parte delle grandi, medie e piccole realtà. Anche noi avremmo potuto adottare una soluzione di condivisione con server centralizzati, questo avrebbe reso più veloce la nostra rete e avrebbe permesso la condivisione di file di più grosse dimensioni, non ché una spesa in termini di sviluppo e mantenimento molto inferiore.
Ma essendo la sicurezza il punto centrale del nostro progetto questa possibilità è stata scartata a priori.
I rischi di tenere i dati tutti si alcuni server sono troppi. Per esempio affidando tutti i dati ad una compagnia di server si rischia che se la compagnia ha problemi tecnici o subisce attacchi i dati rimangano inaccessibili per un periodo di tempi o addirittura cadano persi. Ancora se la sicurezza della azienda venisse compromessa rischieremmo che male intenzionati si approprino dei nostri dati e che questi vengano diffusi.

La tecnologia delle DHT è molto interessante in quanto rappresenta una specie di compromesso tra il modello a server centralizzati e il modello totalmente distribuito.
Però anche in questo caso abbiamo una difficoltà di programmazione notevole e un carico di lavoro dei nodi distribuito non in modo ottimale.

Freenet è il programma che più assomigliava all'idea che avevamo della nostra rete. La modalità di lavoro friend to friend ci avrebbe permesso di usare solo i nodi che volevamo noi, la sicurezza era nettamente al di sopra di quella che ci necessitava, l'informazione in Freenet viene spezzettata in tante parti e inviata con ridondanza a nodi diversi, cifratura dei file e delle connessioni. A fronte di queste considerazioni avevamo preso in considerazione di utilizzare il codice di Freenet come base per sviluppare la nostra idea. Avevamo già determinato che la struttura della rete per sfruttare il cloud sarebbe dovuta essere di due livelli, server e client, inoltre i server non dovevano comunicare tra di loro e a seguito dello studio del codice di Freenet è stato chiaro che le modifiche necessarie sarebbero state più impegnative che sviluppare da zero un programma con le specifiche che avevamo ormai delineato. 

Il nostro software doveva essere prima di tutto realizzato con l'obbiettivo di funzionare ottimamente su servizi di cloud computing. Doveva basarsi su una topologia a due livelli, client e server, in modo da sfruttare le potenzialità offerte dal cloud e alleggerire il carico dei nodi client. Non doveva basarsi su un solo server ma su diversi, in modo da poter attuare una splitting dell'informazione verso questi ultimi. 

Dato che quindi abbiamo avuto l'opportunità di programmare da zero il software abbiamo deciso di renderlo più adattabile a future espansioni dal lato client. Invece che dare una classica veste grafica dalla quale gestire il programma, implementata nel client, abbiamo preferito creare un altra entità di interfacciamento con l'utente. Infatti il nostri client non ha interfaccia grafica, ma viene comandato da messaggi xml. Per utilizzarlo noi abbiamo creato uno script in python da usare come terminale per inviare i comandi al client. Questo è solo un esempio di terminale, ma è utile perché in futuro si potrà comandare il client tramite interfaccia web, piuttosto che con un applicazione per cellulari. 
\section{Struttura di rete}
\begin{figure}
\begin{center}
\includegraphics[width=15.3cm]{img/darkcloud.png}
\end{center}
\caption{Architettura di Darkcloud}
\label{Architettura Darkcloud}
\end{figure}
La rete Darknet è stata progettata con l'obbiettivo di proteggere i dati in essa condivisa.

La struttura di darkcloud si compone di tre tipi di nodi: i {\itshape server},i {\itshape client} e i {\itshape terminali}. 
I {\itshape  terminali} sono le interfaccie grafiche tramite le quali gli utenti interagiscono con il sistema.
I nodi {\itshape  client} sono quelli che eseguono le operazioni che gli utenti inviano tramite i terminali.
I nodi {\itshape server} sono i  delegati al mantenimento del'informazione, costituiti da istanze di cloud computing.
I terminali, i client e i server possono collegarsi tra di loro si tramite rete locale che tramite internet.
La topologia della nostra rete permette a diversi terminali dello stesso utente dicollegarsi ad un unico nodo.
{\itshape Fully connected} sul lato client, cioè tutti i nodi client possono comunicare tra di loro e con tutti i server.
Mentre invece il lato server può comunicare con tutti i client, ma i server non possono comunicare tra di loro.
Questo semplicemente perché non è utile ai fini del loro compito. Mentre invece i client

Gli indirizzi dei vari nodi, sia client che server, sono specificati manualmente nella prima configurazione dei nodi. Quindi i nodi non si aggiungono dinamicamente. Dato le dimensioni contenute che la rete si propone di avere questo è stato più semplice e più sicuro di un approccio dinamico. Per identificare un nodo all'interno della rete si usa una chiave, che è un codice alfanumerico generato da una apposita funzione che ogni nodo conosce, funzione che ricevendo in ingresso l'ip e la porta del nodo restituisce in uscite la chiave di riconoscimento del nodo. In questo modo si crea un nuovo network virtuale sopra la rete internet.

Dopo aver avviato una certa quantità di nodi server e alcuni nodi client, il nostro programma ci permette in modo trasparente di salvare un file nella rete.
Questo file viene elaborato da un protocollo, che si vedrà nel dettaglio nei paragrafi successivi.
Questo protocollo spezzetta i file e ne manda una parte ad ogni server.
Ora il nodo client ha riposto al sicuro il suo file, e può ricomporlo soltanto lui, quindi quello che può ora fare è condividerne la 
conoscenza con altri nodi o ad esigenza richiedere il file al programma.
Di primo acchito le perplessità sulla sicurezza possono essere tante, ma si invita il lettore a leggere il paragrafo che parla 
della sicurezza del nodo.

I servizi di cloud computing che nella implementazione ultima andranno a mantenere i nostri file dovranno essere molteplici. Al momento se qualcuno ha bisogno di un certo numero di server su cui fare girare il proprio software può chiederlo direttamente ad un unico fornitore di servizi cloud. Per esempio per salvare i file in 100 parti diverse potrei chiedere ad un solo fornitore, uno tra Google Amazon Microsoft e altri, di caricare il mio software su 100 istanze che rappresentano sistemi operativi. A questo punto il mio file sarebbe salvato in parti sui server del fornitore scelto. Però questo non sarebbe astuto per tutelare i dati del nostro professionista che li vuole mantenere al sicuro. In quanto essendo dati tutti a disposizione del fornitore nulla gli impedirebbe di ricomporre il file e di provare poi a decrittarlo. Se a questo punto il provider ottenesse i nostri dati potrebbe usarli per ricerche di mercato o profilazione degli utenti. Essendo spesso questi provider di servizi in paesi diversi dal nostro il tutelarsi in tali problemi di privacy diventa complicato. Oppure se un attaccante che trovasse una falla nei sistemi dello stesso fornitore potrebbe fare lo stesso. Ancora se affidiamo tutti i dati allo stesso fornitore in caso di malfunzionamento delle strutture i dati potrebbero essere irraggiungibili per un dato periodo di tempo. Per questi motivi si preferirà utilizzare diversi servizi di cloud computing per avere un certo grado di ridondanza dei dati e non lasciarli tutti nelle mani di un unico operatore.
\section{Software architecture}
\begin{figure}
\begin{center}
\includegraphics[width=15.3cm]{img/nodi.png}
\end{center}
\caption{Darkcloud e NetNode}
\label{Darkcloud e NetNode}
\end{figure}

Lo scopo di Darkcloud è quello di immagazzinare documenti in modo che nessuno che non abbia i permessi possa accedervi, permettendo anche di condividere il file tra più utenti.

Nel nostro software abbiamo 2 tipi di classi usati per identificare i diversi nodi della rete.
La classe Darkcloud.java e la classe Netnode.java. La classe Darkcloud.java è quella che ogni nodo istanza quando nasce. Invece le classi Netnode sono copie degli altri nodi, utilizzate per memorizzare in locale i dati degli altri nodi, come indirizzo, porta di ascolto e molto ancora.

Una nuova tecnologia che sta nascendo e di cui si sente molto parlare è il {\itshape cloud-computing}, grazie a questa tecnologia 
è possibile avere molte istanze di una applicazione senza dover per forza avere un server dedicato per ognuna di esse.
A patto di utilizzare le API di quel determinato fornitore di servizi cloud.
Infatti i metodi all'interno delle nostre classi sono stati sviluppati tramite la {\itshape reflection}, metodo di programmazione che ci permette di creare facilmente comandi incapsulati, in modo da poterli in un secondo momento adattare alle varie API dei diversi servizi di {\itshape cloud-computing} 
senza dover toccare il resto del codice.

Vista la continua evoluzione delle soluzioni hardware portatili come smartphone e tablet abbiamo pensato di fare evolvere anche il nostro software in modo da poterlo fare collaborare con queste tecnologie.
Infatti quando avviamo l'applicazione non è direttamente questa che andiamo ad usare per caricare i dati, ma sono dei terminali i quali poi contattano il client.
Per esempio al momento abbiamo sviluppato uno script in python che si chiama client.py tramite il quale, dopo aver avviato il nostro client, possiamo inviare ricevere e condividere file sulla rete. Adottando una soluzione del genere quando in un secondo momento, o a seconda di esigenze, si vorrà sviluppare una applicazione per tablet, o una applicazione web che ci permetta di usare la nostra rete da browser o ancora integrare l'uso della rete in altri software non sarà necessario andare a modificare il programma client ma semplicemente creare una interfaccia. Per poter rendere questo possibile il nostro utente dovrà avere un pc connesso ad internet che gestirà tutte le richieste che le sue diverse interfacce inoltreranno. Un po come un convogliatore di richieste ed invii. Questo rende molto più semplice lo sviluppo di nuove soluzioni per usare darkcloud.
\section{Protocollo di comunicazione tra nodi}
Le connessioni tra i vari nodi avvengono tramite connessioni criptate con il protocollo {\itshape SSL}. Il Secure Socket Layer, SSL, è un protocollo crittografico che permette una comunicazione sicura su reti TCP/IP, come nel nostro caso reti lan o internet. La cifratura avviene al di sopra del livello di trasporto. 
Questo protocollo consente alle applicazioni client/server di comunicare attraverso una rete in modo tale da prevenire il 'tampering' (manomissione) dei dati, la falsificazione e l'intercettazione.
L'autenticazione è bilaterale, cioè entrambi le parti si autenticano scambiandosi i certificati. Certificati che vengono generati alla creazione del nodo. In seguito questi certificati si scambiano tra i diversi nodi e tramite uno script apposito vengono aggiunti tra i certificati riconosciuti come 'trusted' per la nostra rete.

I messaggi che viaggiano tra i nodi criptati tramite SSL sono messaggi in formato XML. Questo formato è stato scelto perché permette in maniera molto semplice di aggiungere al messaggio campi e attributi. 

I messaggi XML scambiati si dividono principalmente in due tipi: i messaggi Request e i messaggi Response. Quando un nodo vuole comunicare con un altro crea un istanza di un oggetto request, successivamente specifica di che tipo di richiesta si tratta, aggiunge i campi con le informazioni necessarie affinché il nodo ricevente possa soddisfare la richiesta, e tramite il metodo send invia il messaggio all'altro nodo. Il metodo send si preoccupa di creare la connessione con il secondo nodo e di raccoglierne la risposta cioè un messaggio contenente un oggetto response che contiene la risposta del secondo nodo. Infatti una volta che il nodo ricevente ha la richiesta si preoccupa di vedere di che tipo si tratta, e in base a quello esegue il codice corrispondente a quel tipo di richiesta. Elabora i dati contenuti nella richiesta, crea una istanza di response, ci mette i risultati e li invia al richiedente.

I tipi di messaggi che i nodi si possono scambiare sono:
\begin{itemize}
	\item PING
	\item PUT
	\item GET
	\item SHARE
	\item RECEIVE
\end{itemize}

Il primo comando che andiamo ad analizzare è il PING.
Questo tipo di request viene usato dai nodi per verificare se gli altri sono online e quanto sono distanti calcolando i tempi di latenza.
Infatti è un comando che può essere usato anche dal nostro script client.py per verificare se i nodi client, tramite i quali possiamo mandare i file sulla rete, sono vivi. Ancora i nodi client effettuano un ping regolarmente verso i server in modo che quando devono caricare file sulla rete sappiano già quanti server sono disponibili e quindi in quante parti possono suddividere il file. Oltre a effettuare il ping regolare dei server si effettua anche quello degli altri client, in modo da effettuare le condivisioni dei file con loro in modo veloce. 
\section{Salvataggio e recupero dei file}
Quando uno dei nostri client decide di caricare un file sulla nostra rete darkcloud, utilizza il comando PUT. Come abbiamo accennato prima parlando dell'architettura del software, noi abbiamo un interfaccia o molteplici, tramite le quali possiamo comandare il nostro client. Quando inviamo da un interfaccia un comando per salvare sulla rete il file, dal nostro script client.py per esempio,specifichiamo il nome del file locale, il nome con cui vogliamo che il file venga salvato e il client che dobbiamo usare. L'interfaccia specificherà quindi al client che abbiamo indicato il contenuto del file e un comando di put tramite un messaggio XML, il nostro client controllerà prima l'integrità del file poi lo cripterà, con specifiche che vedremo in dettaglio nel prossimo capitolo. Dopo di che in base a quanti server il client avrà a disposizione frammenterà il file in tante parti quanti sono i server. Procederà poi a preparare tanti oggetti request quanto sono i frammenti, nei quali specificherà che si tratta di messaggi put, quale è il contenuto del file, il checksum per controlli di integrità e infine invierà la richiesta ai server con il metodo send. Accertandosi che i server rispondano in maniera affermativa di aver ricevuto il frammento e di averlo correttamente salvato.Per poter ricomporre il file il client salverà su un database interno i dettagli dei file e di ogni frammento, compreso il checksum di ognuno e il nodo server sul quale è stato salvato.

L'operazione di recupero viene effettuata dalle interfacce. Nel caso del nostro client.py dobbiamo specificare il client che vogliamo usare, e il nome con il quale il file è salvato in remoto. Quindi l'interfaccia client.py invierà al client una richiesta di tipo GET specificando il nome del file.
Il client a sua volta ricevuta la request recupera il campo con il nome e va a cercare nel sua database i dettagli di come e dove è stato salvato il file. Quindi su quali server, in quale ordine e quali sono i checksum delle singole parti. Una volta inviate le request ai server specificando i nomi dei frammenti, recupera le response mandate dai server. Ora può controllare l'integrità dei file calcolando il checksum dei frammenti ricevuti e confrontandolo con il checksum che aveva salvato. Se i dati sono corretti ricompone il file e lo decripta, inviandolo per concludere all'interfaccia che glielo aveva richiesto.

\section{Condivisione dei file}
Fino ad ora abbiamo visto a grandi linee il funzionamento del salvataggio e del recupero del file, ma dato che questa rete deve permettere a persone di condividere tra di loro file è stato anche implementato un comando SHARE. Questo comando non va a toccare i server, in quanto non avrebbe avuto senso replicare i file sulla rete per ogni utente, infatti quello che abbiamo permesso con il comando share è stato la condivisione della conoscenza di un comando con un altro nodo.
Se un ipotetico utente1 volesse condividere un file con l'utente2 sarà sufficiente usare il comando share.
Dato che la conoscenza e i dati sono salvati sul client e non sulle interfacce, sarà l'utente1 che chiederà tramite la sua interfaccia al suo client di inviare al client di utente2 i dati riguardanti un determinato file. In modo che in un secondo momento se l'utente2 vuole recuperare il file possa semplicemente chiederlo al suo client tramite la sua interfaccia. La procedura parte con l'utente1 che invia tramite la sua interfaccia un richiesta al suo client specificando il nome del file remoto, e i parametri del client di utente2, nel nostro caso specifico di client.py per esempio si tratta dell'indirizzo ip e della porta di ascolto. Il client di utente1 andrà a recuperare dal suo database tutti i dati necessari a recuperare il file. Ora creerà un oggetto request di un tipo RECEIVE e gli allegherà tali dati. Il comando receive serve per salvare nel database locale  i dati di un file, e dei suoi frammenti, che non è stato caricato nella rete dal nodo che esegue il comando. Quindi a seguito della ricezione dei dati e dell'esecuzione del comando receive il client dell'utente2 sarà in grado come l'utente1 di recuperare il file.
\section{Sicurezza del nodo}
E' vero che il mantenere l'indice di tutti i propri file in locale potrebbe essere un punto debole sul piano della sicurezza, ma proprio per questo abbiamo con una serie di accorgimenti reso molto difficile per un attaccante, anche qual'ora avesse compromesso il nodo, reperire le informazioni.
Questo è possibile grazie all'utilizzo combinato , di crittografica simmetrica, crittografia asimmetrica, invio dei dati ai server in modo casuale, utilizzo di comunicazioni criptate secondo il protocollo SSL, controllo in ogni operazione dell'integrità dei file tramite checksum e aggiunta di nodi in modo statico. 
\subsection{Crittografia}
La crittografia asimmetrica, conosciuta anche come crittografia a coppia di chiavi, è un tipo di crittografia usata per condividere file tra due o più utenti. Questo tipo di crittografia permette agli utenti di scambiarsi informazioni in modo che un terzo utente non autorizzato non possa leggere il messaggio. Ogni utente in questo sistema possiede due chiavi di cifratura, una pubblica e una privata. La chiave pubblica viene data a chiunque voglia comunicare con lui, mentre quella privata rimane di esclusiva conoscenza del proprietario. Un messaggio cifrato con la chiave pubblica dell'utente1 può essere decifrato solo tramite la chiave privata dell'utente1. In questo modo se l'utente2 vuole mandare un messaggio cifrato all'utente1, lo cifrerà con la sua chiave pubblica, e solo l'utente1 potrà leggerlo. 
Nel nostro caso abbiamo usato questo metodo per cifrate le parti di file che vengono scambiate tra i nodi. Ogni nodo ha la sua chiave privata e quella pubblica, e inoltre tutti i nodi conoscono le chiavi pubbliche degli altri. In questo modo quando si condividono parti di file tra nodi client e server un male intenzionato che intercettasse i nostri pacchetti non riuscirebbe a carpirne l'informazione. 
I file invece prima di essere spezzettati vengono criptati tramite una chiave simmetrica creata dal nodo stesso. La crittografia simmetrica permette di criptare un file con una chiave, e per decriptare quel file quella chiave è l'unica utilizzabile. In modo che anche se un male intenzionato riuscisse a ricomporre il file infrangendo la crittografia asimmetrica, dovrebbe avere un ulteriore chiave per decifrare il file intero.
Dato che ogni nodo mantiene l'indice dei file in locale, prima di salvare le chiavi di cifratura simmetrica sul database, queste chiavi vengono ulteriormente cifrate tramite la chiave pubblica del nodo locale. In questo modo se qualcuno riuscisse a rubarci il database, senza la nostra chiave privata non riuscirebbe a conoscere le chiavi dei nostri file.
\subsection{Scelte strutturali}
Quando un file è stato spezzettato, ogni parte viene cifrata e poi inviata ai server. 
Se l'invio ai server avvenisse in modo sequenziale e ordinato, un utente che stesse sniffando la nostra connessione riceverebbe i frammenti in ordine facilitandogli notevolmente il lavoro di ricostruzione. Ancora se mettessimo i file in modo ordinato in base ai server chi avesse accesso a questi server potrebbe sapere in che ordine andrebbero riordinati.
Per evitare ciò, dopo aver spezzettato il file e salvato sul database la sequenza esatta il programma mescola i frammenti tra di loro, solo dopo questo li invia ai server.
Per verificare che i dati che vengono scambiati tra i nodi non vengano contraffatti o subiscano modifiche a causa di errori di connessione si è fatto un forte uso dei controlli del checksum. Il checksum è una sequenza di bit che viene calcolata partendo da un file. Il checksum di un file è univoco, quindi se il file viene modificato il checksum non corrisponde più. Prima di inviare un frammento di file ad un server, ad esempio, un client ne calcola il checksum e lo salva sul database. Oltre a ciò salva anche il checksum dell'intero file. Quando in un secondo momento andrà a ricomporre il file, dopo aver recuperato i frammenti andrà a calcolare i checksum di tali frammenti e li confronterà con i checksum salvati. Stesso procedimento dopo aver ricomposto il file, ne calcolerà il checksum e lo confronterà con quello salvato. Questo ci aiuta anche ad evitare errori nelle procedure di ricomposizione dei file.

