\chapter{Progetto}
In questo capitolo si procederà a illustrare le scelte progettuali, il funzionamento a livello logico funzionale del software e della rete che sta dietro Darkcloud.
\section{Obbiettivi di dettaglio}
L'avvento del cloud computing ha dato uno strumento molto potente da poter sfruttare per questo progetto, lo studio delle tecnologie di condivisione di file peer to peer ha dato una visione di insieme di quello che nel corso del tempo è stata l'evoluzione di queste reti. Questo studio ha permesso di avere molti spunti per poi tracciare quella che sarebbe stata la struttura di Darkcloud. 
La dinamicità di alcune reti p2p pure, ad una prima analisi pare una ottima soluzione, visto che avrebbe permesso di realizzare reti che si ampliassero in modo automatico e quindi non sarebbe stato necessario ogni volta che si aggiungeva un server o un client riconfigurare tutti i nodi. Il problema della sicurezza però in una soluzione del genere renderebbe molto più complicato verificare che i nodi aggiunti siano nodi fidati. In una architettura p2p pura inoltre il carico di lavoro è equamente distribuito su tutti nodi in maniera indistinta, questo però nel caso Darkcloud non sarebbe stato adatto, in quanto avendo a disposizione una grande potenza di calcolo e grande larghezza di banda da parte dei nodi cloud contenuti in grandi data-center si sarebbe inutilmente sobbarcato di lavoro i calcolatori degli utenti ultimi che devono invece solo caricare file e poi scaricarli.  Un altro aspetto che ha spinto a scartare l'approccio p2p puro è il carico di lavoro che avrebbe portato realizzare una soluzione altamente dinamica rispetto ad una soluzione statica. La programmazione di un software dinamico richiede molte più parti e una complessità totale molto maggiore. Quindi bisogna considerare a chi è indirizzato il software, quale sarà il suo bacino di utenza, se si intende farlo crescere in futuro e cosi via cercando quindi di impiegare la giusta quantità di risorse.
Non ha senso realizzare un software e una architettura che sopporti migliaia di utenti quando è specificamente richiesto che funzioni per poche decine di persone.

Oggi non è difficile utilizzare un server centrale per concentrare tutte le informazioni e i dati di una azienda, anzi è proprio quello che fanno la maggior parte delle grandi, medie e piccole realtà. Anche in Darkcloud si sarebbe potuto adottare una soluzione di condivisione con server centralizzati, questo avrebbe reso più veloce la rete e avrebbe permesso la condivisione di file di più grosse dimensioni, portando una spesa in termini di sviluppo e mantenimento molto inferiore.
Essendo la sicurezza il punto centrale del progetto questa possibilità è stata scartata a priori.
I rischi di tenere i dati tutti si alcuni server sono troppi. Per esempio affidando tutti i dati ad una compagnia di server si rischia nell'eventualità che la compagnia abbia problemi tecnici o subisca attacchi che i dati rimangano inaccessibili per un periodo di tempo o addirittura vengano persi. Ancora se la sicurezza della azienda venisse compromessa si rischierebbe che male intenzionati si approprino dei dati e che questi vengano diffusi.

La tecnologia delle DHT è molto interessante in quanto rappresenta un compromesso tra il modello a server centralizzati e il modello totalmente distribuito.
Però porta una difficoltà di programmazione notevole e un carico di lavoro dei nodi distribuito non in modo ottimale.

Freenet è il programma che più assomigliava all'idea di Darkcloud. La modalità di lavoro friend to friend avrebbe permesso di usare solo nodi specifici, la sicurezza era nettamente al di sopra di quella necessaria, l'informazione in Freenet viene spezzettata in tante parti e inviata con ridondanza a nodi diversi, cifratura dei file e delle connessioni. A fronte di queste considerazioni si era preso in considerazione di utilizzare il codice di Freenet come base per sviluppare Darkcloud.
Considerando che per sfruttare la topologia Darkcloud sarebbe dovuta essere di due livelli, server e client, inoltre che i server non dovevano comunicare tra di loro è stato chiaro che le modifiche necessarie sarebbero state più impegnative che sviluppare da zero un programma con le specifiche ormai delineate. 

Il software doveva essere prima di tutto realizzato con l'obbiettivo di funzionare ottimamente su servizi di cloud computing. Basandosi su una topologia a due livelli, client e server, in modo da sfruttare le potenzialità offerte dal cloud e alleggerire il carico dei nodi client. Non doveva basarsi su un solo server ma su diversi in modo da poter attuare una splitting dell'informazione verso questi ultimi. 

Data l'opportunità di programmare da zero il software si è deciso di renderlo più adattabile a future espansioni dal lato client. Invece che dare una classica veste grafica dalla quale gestire il client si è preferito creare un altra entità di interfacciamento con l'utente. Infatti il client non ha interfaccia grafica ma viene comandato da messaggi xml. Per utilizzare il client è stato creato uno script in python da usare come terminale per inviare i comandi. Questo è solo un esempio di terminale, ma è utile perché in futuro si potrà comandare il client tramite interfaccia web, piuttosto che con un applicazione per cellulari. 
\section{Struttura di rete}
\begin{figure}
\begin{center}
\includegraphics[width=15.3cm]{img/darkcloud.png}
\end{center}
\caption{Architettura di Darkcloud}
\label{Architettura Darkcloud}
\end{figure}
La rete Darkcloud è stata progettata con l'obbiettivo di proteggere i dati in essa condivisa.

La struttura di Darkcloud si compone di due tipi di nodi: i {\itshape server} e i {\itshape client}. 
I nodi {\itshape  client} sono quelli che eseguono le operazioni che gli utenti inviano tramite i terminali.
I nodi {\itshape server} sono i  delegati al mantenimento del'informazione, costituiti da istanze di cloud computing.
I client e i server possono collegarsi tra di loro sia tramite rete locale che tramite internet.
La topologia della rete permette a diversi terminali dello stesso utente di collegarsi ad un unico nodo.
{\itshape Fully connected} sul lato client, cioè tutti i nodi client possono comunicare tra di loro e con tutti i server.
Invece il lato server può comunicare con tutti i client, ma i server non possono comunicare tra di loro.
Questo semplicemente perché non è utile ai fini del loro compito.

Gli indirizzi dei vari nodi, sia client che server, sono specificati manualmente nella prima configurazione dei nodi. Quindi i nodi non si aggiungono dinamicamente. Dato le dimensioni contenute che la rete si propone di avere questo è stato più semplice e più sicuro di un approccio dinamico. Per identificare un nodo all'interno della rete si usa una chiave, che è un codice alfanumerico generato da una apposita funzione che ogni nodo conosce, funzione che ricevendo in ingresso l'ip e la porta del nodo restituisce in uscite la chiave di riconoscimento del nodo. In questo modo si crea un nuovo network virtuale sopra la rete internet.

Dopo aver avviato una certa quantità di nodi server e alcuni nodi client, il programma permette in modo trasparente di salvare un file nella rete.
Questo file viene elaborato da un protocollo che si vedrà nel dettaglio nei paragrafi successivi.
Questo protocollo spezzetta i file e ne manda una parte ad ogni server.
Ora il nodo client ha riposto al sicuro il suo file, e può ricomporlo soltanto lui, quindi quello che può ora fare è condividerne la 
conoscenza con altri nodi o ad esigenza richiedere il file al programma.
Di primo acchito le perplessità sulla sicurezza possono essere tante, ma si invita il lettore a leggere il paragrafo che parla 
della sicurezza del nodo.

I servizi di cloud computing che nella implementazione ultima andranno a mantenere i file dovranno essere molteplici. Al momento se qualcuno ha bisogno di un certo numero di server su cui fare girare il proprio software può chiederlo direttamente ad un unico fornitore di servizi cloud. Per esempio per salvare i file in 100 parti diverse si potrebbe chiedere ad un solo fornitore, uno tra Google Amazon Microsoft e altri, di caricare il software su 100 istanze che rappresentano sistemi operativi. A questo punto il file sarebbe salvato in parti sui server del fornitore scelto. Però questo non sarebbe astuto per tutelare i dati del professionista che li vuole mantenere al sicuro. In quanto essendo dati tutti a disposizione del fornitore nulla gli impedirebbe di ricomporre il file e di provare poi a decrittarlo. Se a questo punto il provider ottenesse i dati interi potrebbe usarli per ricerche di mercato o profilazione degli utenti. Essendo spesso questi provider di servizi in paesi diversi dall'utilizzatore il tutelarsi in tali problemi di privacy diventa complicato. Oppure se un attaccante che trovasse una falla nei sistemi dello stesso fornitore potrebbe fare lo stesso. Ancora se si affidano tutti i dati allo stesso fornitore in caso di malfunzionamento delle strutture i dati potrebbero essere irraggiungibili per un dato periodo di tempo. Per questi motivi si preferirà utilizzare diversi servizi di cloud computing per avere un certo grado di ridondanza dei dati e non lasciarli tutti nelle mani di un unico operatore.
\section{Architettura software}
\begin{figure}
\begin{center}
\includegraphics[width=15.3cm]{img/nodi.png}
\end{center}
\caption{Darkcloud e NetNode}
\label{Darkcloud e NetNode}
\end{figure}

Lo scopo di Darkcloud è quello di immagazzinare documenti in modo che nessuno che non abbia i permessi possa accedervi, permettendo anche di condividere il file tra più utenti.

Nel software si trovano 2 tipi di entità utilizzate per identificare i diversi nodi della rete.
Le entità Darkcloud e le entità Netnode. Le entità Darkcloud sono quelle che ogni nodo istanza quando nasce. Invece le entità Netnode sono copie degli altri nodi, utilizzate per memorizzare in locale i dati degli altri nodi, come indirizzo, porta di ascolto e molto ancora.

Una nuova tecnologia che sta nascendo e di cui si sente molto parlare è il {\itshape cloud-computing}, grazie a questa tecnologia 
è possibile avere molte istanze di una applicazione senza dover per forza avere un server dedicato per ognuna di esse.
A patto di utilizzare le API di quel determinato fornitore di servizi cloud.
Infatti i metodi all'interno delle classi sono stati sviluppati tramite la {\itshape reflection}, metodo di programmazione che permette di creare facilmente comandi incapsulati, in modo da poterli in un secondo momento adattare alle varie API dei diversi servizi di {\itshape cloud-computing} 
senza dover toccare il resto del codice.

Vista la continua evoluzione delle soluzioni hardware portatili come smartphone e tablet si è pensato di fare evolvere anche il software in modo da poterlo fare collaborare con queste tecnologie.
Infatti quando si avvia l'applicazione non è direttamente questa che si va ad usare per caricare i dati, ma attraverso terminali i quali poi contattano il client.
Per esempio al momento è stato sviluppato uno script in python che si chiama client.py tramite il quale, dopo aver avviato il client, si può inviare ricevere e condividere file sulla rete. Adottando una soluzione del genere quando in un secondo momento, o a seconda di esigenze, si vorrà sviluppare una applicazione per tablet, o una applicazione web che permetta di usare la rete da browser o ancora integrare l'uso della rete in altri software non sarà necessario andare a modificare il programma client ma semplicemente creare una interfaccia. Per poter rendere questo possibile l'utente dovrà avere un pc connesso ad internet che gestirà tutte le richieste che le sue diverse interfacce inoltreranno. Un po come un convogliatore di richieste ed invii. Questo rende molto più semplice lo sviluppo di nuove soluzioni per usare Darkcloud.
\section{Protocollo di comunicazione tra nodi}
Le connessioni tra i vari nodi avvengono tramite connessioni criptate con il protocollo {\itshape SSL}. Il Secure Socket Layer, SSL, è un protocollo crittografico che permette una comunicazione sicura su reti TCP/IP, come reti lan o internet nel caso di Darkcloud. La cifratura avviene al di sopra del livello di trasporto. 
Questo protocollo consente alle applicazioni client/server di comunicare attraverso una rete in modo tale da prevenire il 'tampering' (manomissione) dei dati, la falsificazione e l'intercettazione.
L'autenticazione è bilaterale, cioè entrambi le parti si autenticano scambiandosi i certificati. Certificati che vengono generati alla creazione del nodo. In seguito questi certificati si scambiano tra i diversi nodi e tramite uno script apposito vengono aggiunti tra i certificati riconosciuti come 'trusted' per la rete.

I messaggi che viaggiano tra i nodi criptati tramite SSL sono messaggi in formato XML. Questo formato è stato scelto perché permette in maniera molto semplice di aggiungere al messaggio campi e attributi. 

I messaggi XML scambiati si dividono principalmente in due tipi: i messaggi Request e i messaggi Response. Quando un nodo vuole comunicare con un altro crea un istanza di un oggetto request, successivamente specifica di che tipo di richiesta si tratta, aggiunge i campi con le informazioni necessarie affinché il nodo ricevente possa soddisfare la richiesta, e tramite il metodo send invia il messaggio all'altro nodo. Il metodo send si preoccupa di creare la connessione con il secondo nodo e di raccoglierne la risposta cioè un messaggio contenente un oggetto response che contiene la risposta del secondo nodo. Infatti una volta che il nodo ricevente ha la richiesta si preoccupa di vedere di che tipo si tratta, e in base a quello esegue il codice corrispondente a quel tipo di richiesta. Elabora i dati contenuti nella richiesta, crea una istanza di response, vi inserisce i risultati e li invia al richiedente.

I tipi di messaggi che i nodi si possono scambiare sono:
\begin{itemize}
	\item PING
	\item PUT
	\item GET
	\item SHARE
	\item RECEIVE
\end{itemize}

Il primo comando che si analizzerà è il PING.
Questo tipo di request viene usato dai nodi per verificare se gli altri sono online e quanto sono distanti calcolando i tempi di latenza.
Infatti è un comando che può essere usato anche dallo script client.py per verificare se i nodi client, tramite i quali si può mandare i file sulla rete, sono vivi. Ancora i nodi client effettuano un ping regolarmente verso i server in modo che quando devono caricare file sulla rete sappiano già quanti server sono disponibili e quindi in quante parti possono suddividere il file. Oltre a effettuare il ping regolare dei server si effettua anche quello degli altri client, in modo da effettuare le condivisioni dei file con loro in modo veloce. 
\section{Salvataggio e recupero dei file}
\begin{figure}
\begin{center}
\includegraphics[width=15.3cm]{img/put.png}
\end{center}
\caption{Invio di un file su Darkcloud}
\label{Invio di un file su Darkcloud}
\end{figure}
Quando un client decide di caricare un file sulla rete Darkcloud, utilizza il comando PUT. Come si è accennato prima parlando dell'architettura del software, si ha un interfaccia o molteplici, tramite le quali si può comandare il client. Quando si invia da un interfaccia un comando per salvare sulla rete il file, dallo script client.py per esempio, si specifica il nome del file locale, il nome con cui si vuole che il file venga salvato e il client da usare. L'interfaccia specificherà quindi al client che si è indicato il contenuto del file e un comando di put tramite un messaggio XML, il client controllerà prima l'integrità del file poi lo cripterà, con specifiche che si vedranno in dettaglio nel prossimo capitolo. Dopo di che in base a quanti server il client avrà a disposizione frammenterà il file in tante parti quanti sono i server. Procederà poi a preparare tanti oggetti request quanto sono i frammenti, nei quali specificherà che si tratta di messaggi put, quale è il contenuto del file, il checksum per controlli di integrità e infine invierà la richiesta ai server con il metodo send. Accertandosi che i server rispondano in maniera affermativa di aver ricevuto il frammento e di averlo correttamente salvato.Per poter ricomporre il file il client salverà su un database interno i dettagli dei file e di ogni frammento, compreso il checksum di ognuno e il nodo server sul quale è stato salvato.
\begin{figure}
\begin{center}
\includegraphics[width=15.3cm]{img/get.png}
\end{center}
\caption{Recupero di un file da Darkcloud}
\label{Recupero di un file da Darkcloud}
\end{figure}

L'operazione di recupero viene effettuata dalle interfacce. Nel caso del client.py si deve specificare il client da usare, e il nome con il quale il file è salvato in remoto. Quindi l'interfaccia client.py invierà al client una richiesta di tipo GET specificando il nome del file.
Il client a sua volta ricevuta la request recupera il campo con il nome e va a cercare nel sua database i dettagli di come e dove è stato salvato il file. Quindi su quali server, in quale ordine e quali sono i checksum delle singole parti. Una volta inviate le request ai server specificando i nomi dei frammenti, recupera le response mandate dai server. Ora può controllare l'integrità dei file calcolando il checksum dei frammenti ricevuti e confrontandolo con il checksum che aveva salvato. Se i dati sono corretti ricompone il file e lo decripta, inviandolo per concludere all'interfaccia che glielo aveva richiesto.

\section{Condivisione dei file}
\begin{figure}
\begin{center}
\includegraphics[width=15.3cm]{img/share.png}
\end{center}
\caption{Condivisione di un file con un altro utente}
\label{Condivisione di un file con un altro utente}
\end{figure}
Fino ad ora si è visto a grandi linee il funzionamento del salvataggio e del recupero del file, ma dato che questa rete deve permettere a persone di condividere tra di loro file è stato anche implementato un comando SHARE. Questo comando non va a toccare i server, in quanto non avrebbe avuto senso replicare i file sulla rete per ogni utente, infatti quello che si è permesso con il comando share è stata la condivisione della conoscenza di un comando con un altro nodo.
Se un ipotetico utente1 volesse condividere un file con l'utente2 sarà sufficiente usare il comando share.
Dato che la conoscenza e i dati sono salvati sul client e non sulle interfacce, sarà l'utente1 che chiederà tramite la sua interfaccia al suo client di inviare al client di utente2 i dati riguardanti un determinato file. In modo che in un secondo momento se l'utente2 vuole recuperare il file possa semplicemente chiederlo al suo client tramite la sua interfaccia. La procedura parte con l'utente1 che invia tramite la sua interfaccia un richiesta al suo client specificando il nome del file remoto, e i parametri del client di utente2, nel caso specifico di client.py per esempio si tratta dell'indirizzo ip e della porta di ascolto. Il client di utente1 andrà a recuperare dal suo database tutti i dati necessari a recuperare il file. Ora creerà un oggetto request di un tipo RECEIVE e gli allegherà tali dati. Il comando receive serve per salvare nel database locale  i dati di un file, e dei suoi frammenti, che non è stato caricato nella rete dal nodo che esegue il comando. Quindi a seguito della ricezione dei dati e dell'esecuzione del comando receive il client dell'utente2 sarà in grado come l'utente1 di recuperare il file.
\section{Sicurezza del nodo}
E' vero che il mantenere l'indice di tutti i propri file in locale potrebbe essere un punto debole sul piano della sicurezza, ma proprio per questo si sono adottati una serie di accorgimenti per rendere difficile ad un attaccante, anche qual'ora avesse compromesso il nodo, reperire le informazioni.
Questo è possibile grazie all'utilizzo combinato , di crittografica simmetrica, crittografia asimmetrica, invio dei dati ai server in modo casuale, utilizzo di comunicazioni criptate secondo il protocollo SSL, controllo in ogni operazione dell'integrità dei file tramite checksum e aggiunta di nodi in modo statico. 

Infatti quando un file è stato spezzettato, ogni parte viene cifrata e poi inviata ai server. 
Se l'invio ai server avvenisse in modo sequenziale e ordinato, un utente che stesse sniffando la connessione riceverebbe i frammenti in ordine facilitandogli notevolmente il lavoro di ricostruzione. Ancora se inviassero i file in modo ordinato in base ai server chi avesse accesso a questi server potrebbe sapere in che ordine andrebbero riordinati.
Per evitare ciò, dopo aver spezzettato il file e salvato sul database la sequenza esatta il programma mescola i frammenti tra di loro, solo dopo questo li invia ai server.

Per verificare che i dati che vengono scambiati tra i nodi non vengano contraffatti o subiscano modifiche a causa di errori di connessione si è fatto un forte uso dei controlli del checksum. Il checksum è una sequenza di bit che viene calcolata partendo da un file. Il checksum di un file è univoco, quindi se il file viene modificato il checksum non corrisponde più. Prima di inviare un frammento di file ad un server, ad esempio, un client ne calcola il checksum e lo salva sul database. Oltre a ciò salva anche il checksum dell'intero file. Quando in un secondo momento andrà a ricomporre il file, dopo aver recuperato i frammenti andrà a calcolare i checksum di tali frammenti e li confronterà con i checksum salvati. Stesso procedimento dopo aver ricomposto il file, ne calcolerà il checksum e lo confronterà con quello salvato. Questo aiuta anche ad evitare errori nelle procedure di ricomposizione dei file.

\subsection{Crittografia}
La crittografia asimmetrica, conosciuta anche come crittografia a coppia di chiavi, è un tipo di crittografia usata per condividere file tra due o più utenti. Questo tipo di crittografia permette agli utenti di scambiarsi informazioni in modo che un terzo utente non autorizzato non possa leggere il messaggio. Ogni utente in questo sistema possiede due chiavi di cifratura, una pubblica e una privata. La chiave pubblica viene data a chiunque voglia comunicare con lui, mentre quella privata rimane di esclusiva conoscenza del proprietario. Un messaggio cifrato con la chiave pubblica dell'utente1 può essere decifrato solo tramite la chiave privata dell'utente1. In questo modo se l'utente2 vuole mandare un messaggio cifrato all'utente1, lo cifrerà con la sua chiave pubblica, e solo l'utente1 potrà leggerlo. 
In Darkcloud si è usato questo metodo per cifrate le parti di file che vengono scambiate tra i nodi. Ogni nodo ha la sua chiave privata e quella pubblica, e inoltre tutti i nodi conoscono le chiavi pubbliche degli altri. In questo modo quando si condividono parti di file tra nodi client e server un male intenzionato che intercettasse i  pacchetti non riuscirebbe a carpirne l'informazione. 
I file invece prima di essere spezzettati vengono criptati tramite una chiave simmetrica creata dal nodo stesso. La crittografia simmetrica permette di criptare un file con una chiave, e per decriptare quel file quella chiave è l'unica utilizzabile. In modo che anche se un male intenzionato riuscisse a ricomporre il file infrangendo la crittografia asimmetrica, dovrebbe avere un ulteriore chiave per decifrare il file intero.
Dato che ogni nodo mantiene l'indice dei file in locale, prima di salvare le chiavi di cifratura simmetrica sul database, queste chiavi vengono ulteriormente cifrate tramite la chiave pubblica del nodo locale. In questo modo se qualcuno riuscisse a il database, senza la chiave privata non riuscirebbe a conoscere le chiavi dei file.
